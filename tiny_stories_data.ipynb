{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoKF18od0e1Z",
        "outputId": "2181247e-8ca4-472d-9def-f4bee4745e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ESE5460_final_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrAlvYfT0io6",
        "outputId": "e881a5ce-35d4-4117-9448-e27994dfaa2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ESE5460_final_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "dataset = load_dataset(\"roneneldan/TinyStories\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPRif5360ylw",
        "outputId": "91333484-07a2-4a95-bef4-7a124a8149fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
            "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(dataset)\n",
        "# print(dataset.keys())\n",
        "train_dset = dataset['train']\n",
        "print(train_dset[0])\n",
        "# print(len(train_dset))\n",
        "print(train_dset[0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JlS0grS2KR_",
        "outputId": "6146c860-87eb-4cbb-9eb3-117f6d1162bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\\n\\nLily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\\n\\nTogether, they shared the needle and sewed the button on Lily\\'s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.'}\n",
            "One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
            "\n",
            "Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\n",
            "\n",
            "Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def integer_encode(texts):\n",
        "    word_to_index = {}\n",
        "    index_to_word = {}\n",
        "    encoded_texts = []\n",
        "\n",
        "    # Assign a unique integer to each word\n",
        "    current_index = 1  # Start indexing from 1, leaving 0 for padding if needed\n",
        "    for i in tqdm(range(len(texts))):\n",
        "        text = train_dset[i]['text']\n",
        "        encoded_text = []\n",
        "        for word in text.split():\n",
        "            if word not in word_to_index:\n",
        "                word_to_index[word] = current_index\n",
        "                index_to_word[current_index] = word\n",
        "                current_index += 1\n",
        "            encoded_text.append(word_to_index[word])\n",
        "        encoded_texts.append(encoded_text)\n",
        "\n",
        "    return word_to_index, index_to_word, encoded_texts"
      ],
      "metadata": {
        "id": "H8Q3mjka4Kyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_to_i, i_to_w, encoded_train = integer_encode(train_dset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIPrC0BP2vPD",
        "outputId": "3ce2d137-d1fe-40b8-b5d1-4f8549480f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2119719/2119719 [04:31<00:00, 7798.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_train[0])\n",
        "print(len(w_to_i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr9zGDV53hX9",
        "outputId": "56c8e786-c384-47b1-8fe2-edba20ebdfc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 3, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 15, 21, 15, 16, 22, 7, 23, 18, 24, 25, 9, 20, 11, 26, 27, 28, 29, 30, 3, 31, 32, 11, 33, 7, 34, 18, 11, 35, 36, 37, 38, 39, 8, 40, 41, 42, 43, 24, 15, 20, 44, 36, 30, 45, 46, 47, 35, 48, 36, 37, 49, 50, 51, 52, 24, 25, 9, 36, 53, 54, 55, 56, 57, 58, 25, 9, 36, 59, 25, 31, 32, 60, 33, 61, 16, 62, 17, 63, 64, 21, 57, 65, 66, 36, 67, 68, 69, 70, 57, 71, 7, 72, 11, 35, 63, 66, 25, 9, 36, 73, 11, 33, 74, 75, 76, 77, 21, 57, 78, 58, 36, 79, 80]\n",
            "265840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch and torchvision imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "# device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "iXNkoluh5D-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tran_dataset_input = []\n",
        "tran_dataset_label = []\n",
        "\n",
        "for i in tqdm(range(len(encoded_train))):\n",
        "  try:\n",
        "    tran_dataset_input.append(np.array(encoded_train[i][:100]))\n",
        "    tran_dataset_label.append(np.array(encoded_train[i][1:101]))\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZECqPyDj6p9e",
        "outputId": "4bb73efc-8df8-47a2-b737-996b61bdbe5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2119719/2119719 [00:45<00:00, 46994.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(len(tran_dataset_input[0]))\n",
        "print(len(tran_dataset_input))\n",
        "print(len(tran_dataset_label[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLbdcXMR7NpD",
        "outputId": "df40585e-fcea-4c0f-e684-28d18086981e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "2119719\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + (self.pe[:x.size(0)]).squeeze()\n",
        "        return x\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, input_feature_dim, d_model, nhead, nlayers, embedding_size):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(embedding_size, d_model)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model = d_model, nhead = nhead)\n",
        "        self.transformer = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.linear = nn.Linear(d_model, input_feature_dim)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "\n",
        "    def generate_mask(self, sz):\n",
        "      mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "      mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "      return mask\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            src: Tensor, shape ``[seq_len, batch_size]``\n",
        "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
        "        \"\"\"\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        mask = self.generate_mask(len(x)).to(device)\n",
        "        x = self.transformer(x, mask)\n",
        "\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "j6pz6t5o7Qoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_len = 265840\n",
        "vocab_size = 265840\n",
        "heads = 8\n",
        "layers = 6\n",
        "hidden_size = 3 * vocab_size\n",
        "input_feature_dim = 100\n",
        "tran = TransformerModel(input_feature_dim, hidden_size-(hidden_size % heads), nhead = heads, nlayers = layers,  embedding_size = embed_len).to(device)\n",
        "# print(hidden_size-(hidden_size % heads))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(tran.parameters(), lr = 0.0001)"
      ],
      "metadata": {
        "id": "DwH6U1ED8mrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tran_train_l = []\n",
        "tran_train_e = []\n",
        "tran_val_l = []\n",
        "tran_val_e = []\n",
        "\n",
        "num_epochs = 1\n",
        "i = 0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for sequence in tran_dataset_input:\n",
        "        print(i)\n",
        "        tran.zero_grad()\n",
        "\n",
        "        sequence = torch.from_numpy(sequence.T).long()\n",
        "        sequence = sequence.to(device)\n",
        "        # print(sequence.shape)\n",
        "        output = tran(sequence)\n",
        "\n",
        "        current_labels = torch.from_numpy(tran_dataset_label[i])\n",
        "        current_labels = current_labels.to(device)\n",
        "        # try:\n",
        "        loss = criterion(output,current_labels)\n",
        "        # except:\n",
        "        #   break\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        if (i % 1000) != 0:\n",
        "            optimizer.step()\n",
        "\n",
        "        tran_train_l.append(loss.item())\n",
        "        predicted_labels = torch.argmax(output,dim=1)\n",
        "        train_error = 1.0 - (current_labels == predicted_labels).sum()/(len(sequence)-1)\n",
        "        tran_train_e.append(train_error.item())\n",
        "        i += 1\n",
        "\n",
        "        # if (i % 1000) == 0:\n",
        "        #     # Validation\n",
        "        #     val_sequence = tran_dataset_input[i+1]\n",
        "        #     val_sequence = torch.from_numpy(val_sequence).long().to(device)\n",
        "        #     val_output = tran(val_sequence)\n",
        "        #     val_labels = torch.from_numpy(tran_dataset_label[i+1]).to(device)\n",
        "        #     val_loss = criterion(val_output, val_labels)\n",
        "        #     tran_val_l.append(val_loss.item())\n",
        "        #     future_predicted_labels = torch.argmax(val_output, dim=1)\n",
        "        #     validation_error = 1.0 - (val_labels == future_predicted_labels).sum() / (len(val_sequence) - 1)\n",
        "        #     print(f'training_error: {train_error}')\n",
        "        #     print(f'validation_error: {validation_error}')\n",
        "        #     tran_val_e.append(validation_error.item())\n",
        "        #     print(f'Currently at {(i / len(tran_dataset_input)) * 100}% complete')"
      ],
      "metadata": {
        "id": "0FQHjrdD9KfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7iYNUoVB_pHx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}