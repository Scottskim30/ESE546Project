{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPRif5360ylw",
        "outputId": "91333484-07a2-4a95-bef4-7a124a8149fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset parquet (C:/Users/scott/.cache/huggingface/datasets/roneneldan___parquet/roneneldan--TinyStories-6ac769f186d7da53/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3535949e67db4401afc3e0c8daab41a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "dataset = load_dataset(\"roneneldan/TinyStories\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JlS0grS2KR_",
        "outputId": "6146c860-87eb-4cbb-9eb3-117f6d1162bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': 'One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\\n\\nLily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\\n\\nTogether, they shared the needle and sewed the button on Lily\\'s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.'}\n",
            "One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
            "\n",
            "Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\n",
            "\n",
            "Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\n"
          ]
        }
      ],
      "source": [
        "# print(dataset)\n",
        "# print(dataset.keys())\n",
        "train_dset = dataset['train']\n",
        "print(train_dset[0])\n",
        "# print(len(train_dset))\n",
        "print(train_dset[0]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8Q3mjka4Kyo"
      },
      "outputs": [],
      "source": [
        "def integer_encode(texts):\n",
        "    word_to_index = {}\n",
        "    index_to_word = {}\n",
        "    encoded_texts = []\n",
        "\n",
        "    # Assign a unique integer to each word\n",
        "    current_index = 1  # Start indexing from 1, leaving 0 for padding if needed\n",
        "    for i in tqdm(range(len(texts))):\n",
        "        text = train_dset[i]['text']\n",
        "        encoded_text = []\n",
        "        for word in text.split():\n",
        "            if word not in word_to_index:\n",
        "                word_to_index[word] = current_index\n",
        "                index_to_word[current_index] = word\n",
        "                current_index += 1\n",
        "            encoded_text.append(word_to_index[word])\n",
        "        encoded_texts.append(encoded_text)\n",
        "\n",
        "    return word_to_index, index_to_word, encoded_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIPrC0BP2vPD",
        "outputId": "3ce2d137-d1fe-40b8-b5d1-4f8549480f6e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2119719/2119719 [04:31<00:00, 7798.94it/s]\n"
          ]
        }
      ],
      "source": [
        "w_to_i, i_to_w, encoded_train = integer_encode(train_dset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr9zGDV53hX9",
        "outputId": "56c8e786-c384-47b1-8fe2-edba20ebdfc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 3, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 15, 21, 15, 16, 22, 7, 23, 18, 24, 25, 9, 20, 11, 26, 27, 28, 29, 30, 3, 31, 32, 11, 33, 7, 34, 18, 11, 35, 36, 37, 38, 39, 8, 40, 41, 42, 43, 24, 15, 20, 44, 36, 30, 45, 46, 47, 35, 48, 36, 37, 49, 50, 51, 52, 24, 25, 9, 36, 53, 54, 55, 56, 57, 58, 25, 9, 36, 59, 25, 31, 32, 60, 33, 61, 16, 62, 17, 63, 64, 21, 57, 65, 66, 36, 67, 68, 69, 70, 57, 71, 7, 72, 11, 35, 63, 66, 25, 9, 36, 73, 11, 33, 74, 75, 76, 77, 21, 57, 78, 58, 36, 79, 80]\n",
            "265840\n"
          ]
        }
      ],
      "source": [
        "print(encoded_train[0])\n",
        "print(len(w_to_i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXNkoluh5D-y"
      },
      "outputs": [],
      "source": [
        "# torch and torchvision imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "# device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZECqPyDj6p9e",
        "outputId": "4bb73efc-8df8-47a2-b737-996b61bdbe5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2119719/2119719 [00:45<00:00, 46994.50it/s]\n"
          ]
        }
      ],
      "source": [
        "tran_dataset_input = []\n",
        "tran_dataset_label = []\n",
        "\n",
        "for i in tqdm(range(len(encoded_train))):\n",
        "  try:\n",
        "    tran_dataset_input.append(np.array(encoded_train[i][:100]))\n",
        "    tran_dataset_label.append(np.array(encoded_train[i][1:101]))\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLbdcXMR7NpD",
        "outputId": "df40585e-fcea-4c0f-e684-28d18086981e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "2119719\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(len(tran_dataset_input[0]))\n",
        "print(len(tran_dataset_input))\n",
        "print(len(tran_dataset_label[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6pz6t5o7Qoz"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + (self.pe[:x.size(0)]).squeeze()\n",
        "        return x\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, input_feature_dim, d_model, nhead, nlayers, embedding_size):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(embedding_size, d_model)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model = d_model, nhead = nhead)\n",
        "        self.transformer = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.linear = nn.Linear(d_model, input_feature_dim)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "\n",
        "    def generate_mask(self, sz):\n",
        "      mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "      mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "      return mask\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            src: Tensor, shape ``[seq_len, batch_size]``\n",
        "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
        "        \"\"\"\n",
        "        x = self.embedding(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        mask = self.generate_mask(len(x)).to(device)\n",
        "        x = self.transformer(x, mask)\n",
        "\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwH6U1ED8mrb"
      },
      "outputs": [],
      "source": [
        "embed_len = 265840\n",
        "vocab_size = 265840\n",
        "heads = 8\n",
        "layers = 6\n",
        "hidden_size = 3 * vocab_size\n",
        "input_feature_dim = 100\n",
        "tran = TransformerModel(input_feature_dim, hidden_size-(hidden_size % heads), nhead = heads, nlayers = layers,  embedding_size = embed_len).to(device)\n",
        "# print(hidden_size-(hidden_size % heads))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(tran.parameters(), lr = 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FQHjrdD9KfI"
      },
      "outputs": [],
      "source": [
        "tran_train_l = []\n",
        "tran_train_e = []\n",
        "tran_val_l = []\n",
        "tran_val_e = []\n",
        "\n",
        "num_epochs = 1\n",
        "i = 0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for sequence in tran_dataset_input:\n",
        "        print(i)\n",
        "        tran.zero_grad()\n",
        "\n",
        "        sequence = torch.from_numpy(sequence.T).long()\n",
        "        sequence = sequence.to(device)\n",
        "        # print(sequence.shape)\n",
        "        output = tran(sequence)\n",
        "\n",
        "        current_labels = torch.from_numpy(tran_dataset_label[i])\n",
        "        current_labels = current_labels.to(device)\n",
        "        # try:\n",
        "        loss = criterion(output,current_labels)\n",
        "        # except:\n",
        "        #   break\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        if (i % 1000) != 0:\n",
        "            optimizer.step()\n",
        "\n",
        "        tran_train_l.append(loss.item())\n",
        "        predicted_labels = torch.argmax(output,dim=1)\n",
        "        train_error = 1.0 - (current_labels == predicted_labels).sum()/(len(sequence)-1)\n",
        "        tran_train_e.append(train_error.item())\n",
        "        i += 1\n",
        "\n",
        "        # if (i % 1000) == 0:\n",
        "        #     # Validation\n",
        "        #     val_sequence = tran_dataset_input[i+1]\n",
        "        #     val_sequence = torch.from_numpy(val_sequence).long().to(device)\n",
        "        #     val_output = tran(val_sequence)\n",
        "        #     val_labels = torch.from_numpy(tran_dataset_label[i+1]).to(device)\n",
        "        #     val_loss = criterion(val_output, val_labels)\n",
        "        #     tran_val_l.append(val_loss.item())\n",
        "        #     future_predicted_labels = torch.argmax(val_output, dim=1)\n",
        "        #     validation_error = 1.0 - (val_labels == future_predicted_labels).sum() / (len(val_sequence) - 1)\n",
        "        #     print(f'training_error: {train_error}')\n",
        "        #     print(f'validation_error: {validation_error}')\n",
        "        #     tran_val_e.append(validation_error.item())\n",
        "        #     print(f'Currently at {(i / len(tran_dataset_input)) * 100}% complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iYNUoVB_pHx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
